---

layout: post
title:  "Python_ urllib을 이용해 웹 데이터 읽어오기"
author: fennec-fox
tags: 모두를_위한_파이썬
subtitle: "모두를 위한 파이썬 / 웹 스크래핑_ urllib"
category:  blog

---

### 모두를 위한 파이썬 [웹 스크래핑] 내용 정리

<br>

- **[urllib 라이브러리 사용법](<https://python.bakyeono.net/chapter-11-5.html>)**

파이썬의 `urllib` 을 사용하여 웹브라우저를 만들어 봅시다. 

`urllib`은 연결을 만들고, GET 요청을 전송하고, 새로운 줄을 보내거나, 데이터를 받거나, 헤더를 처리하거나

등등의 모든 것을 다 합니다.

```python

# 라이브러리를 가져옵니다.
>>> import urllib.request, urllib.parse, urllib.error


# urlopen 을 부르고 url 을 넣어줍니다. 문자열이 자동 인코딩 됩니다.
# 요청을 해서 받은 데이터를 fhand에 객체형태로 반환합니다.
>>> fhand = urllib.request.urlopen('http://www.dr-chuck.com/page1.htm')


# fhand type = http.client.HTTPResponse
>>> print(fhand)
<http.client.HTTPResponse object at 0x103903080>


# line 으로 한 줄씩 문자열이 바이트로 들어옵니다.
# 디코딩은 자동이 아니므로 decode() 함수를 사용합니다. 
>>> for line in fhand:
      print(line.decode().strip())



 
# urlopen() 함수가 암묵적으로 <head>를 생략한다.    


{% raw %}
<h1>The First Page</h1>
<p>
If you like, you can switch to the
<a href="http://www.dr-chuck.com/page2.htm">
Second Page</a>.
</p> 

{% endraw %}

```

`urllib` 은 라이브러리이면서, 몇가지 모듈로 구성되어 있고, 함수도 있다. 

그리고, 불러온 데이터는 파일의 문자열을 처리하는 방법과 같습니다.

<br>

- 크롤러 : 웹페이지를 읽어와서 웹크롤러 데이터베이스에 저장하는 것 >> 파이썬을 사용하면 좋음  